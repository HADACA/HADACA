{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, mean_squared_error, log_loss\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import ADASYN, SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0) Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_data shape: (20103, 687)\n",
      "df_metadata shape: (685, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dmprocr_ID</th>\n",
       "      <th>indiv</th>\n",
       "      <th>sample</th>\n",
       "      <th>trscr</th>\n",
       "      <th>cnv</th>\n",
       "      <th>meth</th>\n",
       "      <th>gender</th>\n",
       "      <th>days_to_birth</th>\n",
       "      <th>tumor_stage</th>\n",
       "      <th>da</th>\n",
       "      <th>fut</th>\n",
       "      <th>age_diag</th>\n",
       "      <th>days_to_death</th>\n",
       "      <th>tissue_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97-7552-01</td>\n",
       "      <td>97-7552</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>-25578.0</td>\n",
       "      <td>stage ib</td>\n",
       "      <td>alive</td>\n",
       "      <td>1932.0</td>\n",
       "      <td>25578.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>patho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44-7671-01</td>\n",
       "      <td>44-7671</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>-23538.0</td>\n",
       "      <td>stage ib</td>\n",
       "      <td>alive</td>\n",
       "      <td>889.0</td>\n",
       "      <td>23538.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>patho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86-7953-01</td>\n",
       "      <td>86-7953</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>-25315.0</td>\n",
       "      <td>stage ia</td>\n",
       "      <td>alive</td>\n",
       "      <td>997.0</td>\n",
       "      <td>25315.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>patho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L4-A4E5-01</td>\n",
       "      <td>L4-A4E5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>-17680.0</td>\n",
       "      <td>stage i</td>\n",
       "      <td>alive</td>\n",
       "      <td>578.0</td>\n",
       "      <td>17680.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>patho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NJ-A4YP-01</td>\n",
       "      <td>NJ-A4YP</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>-19106.0</td>\n",
       "      <td>stage ib</td>\n",
       "      <td>alive</td>\n",
       "      <td>50.0</td>\n",
       "      <td>19106.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>patho</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dmprocr_ID    indiv  sample  trscr  cnv  meth  gender  days_to_birth  \\\n",
       "0  97-7552-01  97-7552       1      1    1     1    male       -25578.0   \n",
       "1  44-7671-01  44-7671       1      0    1     1    male       -23538.0   \n",
       "2  86-7953-01  86-7953       1      1    1     1  female       -25315.0   \n",
       "3  L4-A4E5-01  L4-A4E5       1      1    1     1  female       -17680.0   \n",
       "4  NJ-A4YP-01  NJ-A4YP       1      1    1     1    male       -19106.0   \n",
       "\n",
       "  tumor_stage     da     fut  age_diag  days_to_death tissue_status  \n",
       "0    stage ib  alive  1932.0   25578.0            NaN         patho  \n",
       "1    stage ib  alive   889.0   23538.0            NaN         patho  \n",
       "2    stage ia  alive   997.0   25315.0            NaN         patho  \n",
       "3     stage i  alive   578.0   17680.0            NaN         patho  \n",
       "4    stage ib  alive    50.0   19106.0            NaN         patho  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chargement des données, clean_data étant les données nettoyées des NaN trop nombreux\n",
    "df_data = pd.read_csv(\"clean_data.csv\")\n",
    "print(\"df_data shape:\", df_data.shape)\n",
    "df_metadata = pd.read_csv(\"metadata.csv\")\n",
    "print(\"df_metadata shape:\", df_metadata.shape)\n",
    "df_metadata[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(685, 20103)\n",
      "labelsBinary : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0\n",
      " 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "valuesBinary : Index(['patho', 'normal'], dtype='object')\n",
      "labelsStages : [ 0  0  1  2  0  3  1  4  0  1  0  3  0  5  0  0  5  1  0  6  4  1  1 -1\n",
      " -1  0  1  1  1  0  7 -1  7  0  0  1  4  5  0  0  8  5  6  9  5  7  6 -1\n",
      "  5  3  1  1  1  5  7  5  3 -1 -1  0  5  0  4  7  0  0 -1  1 -1  1  5 -1\n",
      "  5  5  0  1  5 -1  0  3  1  7  3  5  0  5  3  5  0 -1  5  3  0  1  1  0\n",
      " -1  3  7  0  1 -1  5  2  0  5  4  1  0  9  0  3  0  1  0  3  5 -1 -1  5\n",
      " -1  3  1  3  5  9  1  4  0  1  1 -1  5  0  5  0  3  1  1 -1 -1  1  0  0\n",
      "  7  3  1  0  0  3  5  1  1  0  0  0  0  1  3  1  3  1  3  3  1  0  1  0\n",
      "  9 -1 -1  3  0  5  1  7  1  1  1  4  7  3  0  3  5  5  9  1  0  7 -1  1\n",
      "  1  0  3  7  6  1  5  5  5  5  3  0  0  1  1  7  1  1 -1  0  1  0  7  7\n",
      "  0  0  3  0  1  5  1  1  7  0  0  7  1  1  1  1  7  9  7  0  1 -1 -1  0\n",
      "  6  1  0  5  7 -1  5  3  5  3  3  0  1  5  0  5  0  0  3  7  3  5  1  0\n",
      "  3  1  1  4  1  5  0  3  4  1  1  3  1  1  3  0  0  1  1  7  0  5  1  1\n",
      "  5  5  1  1 -1  1  5  0  1  1  3  5  4 -1  3  5 -1  4  7  3  3  0  5  7\n",
      "  0  1  1  1 -1  0  3 -1  3 -1 -1  0  0  1  5  3  1  1  4  3  0  7  0  7\n",
      "  7  3  0 -1  4  1  9  0  3  5  0  1  0  7  0 -1  1 -1  1  0  1  5 -1  0\n",
      "  1  0  1  0  3  1  7  5  1 -1  0  0 -1  1  3  4  0  1  0  3  0  1  6 -1\n",
      "  5  0  1  1  0 -1 -1  3  1  7  4  1  4 -1  3  3  1  2 -1  7  7  5  0  0\n",
      "  1  3  2  3  7  4  5  3  0  7  5 -1  3  0  1  1  1  1  7  3  7  9  1  9\n",
      " -1 -1  5  3  5  5  3  1  1  5  0  1  0  7 -1  4  0  0  3  3  1  0  4  1\n",
      "  0  1  5  1  0  7  0  3  1  1 -1  7 -1  3  0  5  0  7  2  0  1  0  1  1\n",
      "  0  7  5  0  0  1  0  5  0  0  0  0  7  3  3  7  0  1  3  0  7  4 -1  3\n",
      "  1  5  3  1  3  3  3  4  7  1  0  4  3  0  5  6  0  0  0  1  0  0  4  0\n",
      "  7 -1  3 -1  0  0  3  5  5  1  1  1  3  5  1  5  6 -1  3  5  3  0  0  5\n",
      "  1  1  1  7  5  7  0  5  0  3  1  0  0  0  3 -1  1  1  0  1  4 -1  1  0\n",
      "  1  5  0  1  0  9  1  5  5  5  1  5  4 -1  0  7  3  5 -1  0 -1  0 -1  4\n",
      "  0  1  1  4  6  1  0  0  5  0  4  0  1  5  9  9 -1  3  1  0  0  3  5  0\n",
      "  4  0  3  4  3  0  1  3  0  5  1  0  0  6  0  1  0  1  0  1  1  1  5  0\n",
      "  1  1  5  3  0  1  7  0  0  5  5  5  1  3  1  0  7  7  0  0  7  0  0  0\n",
      "  3  4  3  0  5  3  1  0  9  3  9  3  9]\n",
      "valuesStages : Index(['stage ib', 'stage ia', 'stage i', 'stage iib', 'stage iv',\n",
      "       'stage iiia', 'not reported', 'stage iia', 'stage ii', 'stage iiib'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Convertir les données en ndarray et supprimer les colonnes inutiles\n",
    "D = df_data.loc[:, ~df_data.columns.str.contains('^Unnamed')].values\n",
    "D = D.T\n",
    "\n",
    "print(type(D))\n",
    "print(D.shape)\n",
    "\n",
    "# Générer les labels en fonction d'une colonne choisie\n",
    "status = pd.Series(df_metadata[\"tissue_status\"].values)\n",
    "stage = pd.Series(df_metadata[\"tumor_stage\"].values)\n",
    "\n",
    "labelsBinary, valuesBinary = pd.factorize(status)\n",
    "labelsStages, valuesStages = pd.factorize(stage)\n",
    "\n",
    "yBinary = labelsBinary\n",
    "yStage = labelsStages\n",
    "\n",
    "print(\"labelsBinary :\", labelsBinary)\n",
    "print(\"valuesBinary :\", valuesBinary)\n",
    "\n",
    "print(\"labelsStages :\", labelsStages)\n",
    "print(\"valuesStages :\", valuesStages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(685, 1000)\n"
     ]
    }
   ],
   "source": [
    "# IL FAUT ARRIVER À 300 MB après avoir agrandi le nombre d'observations\n",
    "# ===>>> couper les features\n",
    "# selection des k best features grâce au test chi2\n",
    "chi2_selector = SelectKBest(chi2, k=1000)\n",
    "D = chi2_selector.fit_transform(D, labelsBinary)\n",
    "print(D.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enrichissement artificiel des données\n",
    "\n",
    "Problème potentiel: il reste peut-être des classes 8 dans le test set, potentiellement à nettoyer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 141, 1: 131, 5: 68, 3: 63, -1: 49, 7: 42, 4: 26, 9: 13, 6: 9, 2: 5, 8: 1})\n",
      "(547, 1000)\n",
      "(1000,)\n",
      "(548, 1000)\n",
      "[ 0  0  7  1  7  0  5  3  4 -1  0  0  5  0  7  0  6 -1  1  3  0  0  1  1\n",
      "  3 -1  1  5  1  5  0  3  0  4  7  7  3  3  0  0  1  0  0  0  4 -1 -1 -1\n",
      "  1  0  1  0 -1  0  9  6  5  0  0  0 -1  3  1  7  0  0  5  0  1  1  1  1\n",
      " -1  5  4  3  4  3 -1  0  7  0  5  1  1  6  1  9  1  0  7  5  1  1  0  5\n",
      "  7  0  5  0  3  0  3  0  0  6  7  0  1  1  5  3  7  0  1  5  5  1  1  7\n",
      "  0  1  0 -1 -1  0  1  0  0 -1  9  0 -1  0  3  1  0  7  5  1  3 -1  1  1\n",
      "  7  0  1  1  0  1  1  6  5  7  9  1  1  0  7  3  1  1  0  7  4  4  3  5\n",
      "  5  3  5 -1 -1  0  7  3  0  1  3  6  0  9  0  6  0  4  0  3 -1  1  7 -1\n",
      "  3  1  4  0  1  4  1  1  1  5  0 -1  9  1  0  1  1 -1  5  5  0 -1  3  4\n",
      "  0  1  7 -1  1  1  1  1  7  3  7  0  0  4  5  5  0  3  2  5  7 -1  1  7\n",
      "  0  5  1  0  1  1  0  1  3  1  5  1 -1  0  3  0  7  1  5  3  9 -1  0  5\n",
      "  1  1  5  1  9  9  3  3  0  0  1  1 -1 -1  5  1  1  1  0  0  0  2  0  0\n",
      "  6  0  3  0  5  5  5  1  7  1  7  7  7  5 -1  0  1  4 -1  5  5  4  5  1\n",
      "  0  3  5  5  1  1  1  1  5  5 -1  1  1 -1  0  0  0  4  1  0  3  5 -1  0\n",
      "  1  3  1  0 -1  0  5  0  1  0  3  1  9  3  0 -1  0  0  4  3  4  3  0  0\n",
      "  0  1  0  1  1  3  3  3  0  5  3  1  5  0  3  1  1 -1  5  0  0  3  0  4\n",
      "  7  1  1  3  4  5  0  0  7  5  1  9  1  0  2  4 -1  3  1  0  5  7  1  0\n",
      "  0  1  5  3  0  1  5  0  1  0  1  3 -1  5  1  1  0  6  0  1 -1  1  1 -1\n",
      "  5  0  0  0  3  7 -1  0 -1 -1  7  5  5  1  0  1  0  0  5  5  3  3  1  4\n",
      "  5  0  7  0  0  0  0  7  3  1  0  1  3  0  0  7  1  9  5  5  1  7  2  1\n",
      "  5  0 -1  0  1  3  1  1  0  3  3  4  7  3 -1  0  5  1  5  1  0  1  1  1\n",
      "  0  0  7  1  5  3  1  7  0  3 -1  2  0  1  1  1  1  3  1  1  0  4  0  0\n",
      "  3  3  1  0  0 -1  5  5  4  7 -1  3  9  4 -1  4  0  3  5]\n",
      "[ 0  0  7  1  7  0  5  3  4 -1  0  0  5  0  7  0  6 -1  1  3  0  0  1  1\n",
      "  3 -1  1  5  1  5  0  3  0  4  7  7  3  3  0  0  1  0  0  0  4 -1 -1 -1\n",
      "  1  0  1  0 -1  0  9  6  5  0  0  0 -1  3  1  7  0  0  5  0  1  1  1  1\n",
      " -1  5  4  3  4  3 -1  0  7  0  5  1  1  6  1  9  1  0  7  5  1  1  0  5\n",
      "  7  0  5  0  3  0  3  0  0  6  7  0  1  1  5  3  7  0  1  5  5  1  1  7\n",
      "  0  1  0 -1 -1  0  1  0  0 -1  9  0 -1  0  3  1  0  7  5  1  3 -1  1  1\n",
      "  7  0  1  1  0  1  1  6  5  7  9  1  1  0  7  3  1  1  0  7  4  4  3  5\n",
      "  5  3  5 -1 -1  0  7  3  0  1  3  6  0  9  0  6  0  4  0  3 -1  1  7 -1\n",
      "  3  1  4  0  1  4  1  1  1  5  0 -1  9  1  0  1  1 -1  5  5  0 -1  3  4\n",
      "  0  1  7 -1  1  1  1  1  7  3  7  0  0  4  5  5  0  3  2  5  7 -1  1  7\n",
      "  0  5  1  0  1  1  0  1  3  1  5  1 -1  0  3  0  7  1  5  3  9 -1  0  5\n",
      "  1  1  5  1  9  9  3  3  0  0  1  1 -1 -1  5  1  1  1  0  0  0  2  0  0\n",
      "  6  0  3  0  5  5  5  1  7  1  7  7  7  5 -1  0  1  4 -1  5  5  4  5  1\n",
      "  0  3  5  5  1  1  1  1  5  5 -1  1  1 -1  0  0  0  4  1  0  3  5 -1  0\n",
      "  1  3  1  0 -1  0  5  0  1  0  3  1  9  3  0 -1  0  0  4  3  4  3  0  0\n",
      "  0  1  0  1  1  3  3  3  0  5  3  1  5  0  3  1  1 -1  5  0  0  3  0  4\n",
      "  7  1  1  3  4  5  0  0  7  5  1  9  1  0  2  4 -1  3  1  0  5  7  1  0\n",
      "  0  1  5  3  0  1  5  0  1  0  1  3 -1  5  1  1  0  6  0  1 -1  1  1 -1\n",
      "  5  0  0  0  3  7 -1  0 -1 -1  7  5  5  1  0  1  0  0  5  5  3  3  1  4\n",
      "  5  0  7  0  0  0  0  7  3  1  0  1  3  0  0  7  1  9  5  5  1  7  2  1\n",
      "  5  0 -1  0  1  3  1  1  0  3  3  4  7  3 -1  0  5  1  5  1  0  1  1  1\n",
      "  0  0  7  1  5  3  1  7  0  3 -1  2  0  1  1  1  1  3  1  1  0  4  0  0\n",
      "  3  3  1  0  0 -1  5  5  4  7 -1  3  9  4 -1  4  0  3  5  2]\n"
     ]
    }
   ],
   "source": [
    "# 6 occurences nécessaire pour Smote ou Adasyn, \n",
    "# on enlève la classe 8 et on duplique une occurence de 2 pour passer à 6 (min SMOTE) \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(D, yStage, test_size=0.2, random_state=42)\n",
    "# stratify=y, mais une classe avec 1 occurences,on vire cette classe?\n",
    "\n",
    "recounted = Counter(y_train)\n",
    "print(recounted)\n",
    "\n",
    "X_train_sans_8 = X_train[np.where(y_train!=8)]\n",
    "X_2 = X_train[np.where(y_train==2)][0]\n",
    "print(X_train_sans_8.shape)\n",
    "print(X_2.shape)\n",
    "\n",
    "# dédoublement d'un exemple de la classe 2\n",
    "X_train_sans_8_double_2 = np.vstack([X_train_sans_8,X_2])\n",
    "print(X_train_sans_8_double_2.shape)\n",
    "\n",
    "# dédoublement d'un label de la classe 2\n",
    "y_train_sans_8 = y_train[np.where(y_train!=8)]\n",
    "print(y_train_sans_8)\n",
    "y_train_sans_8 = np.append(y_train_sans_8, 2)\n",
    "print(y_train_sans_8)\n",
    "\n",
    "# retrait des instances potentielles de la classe 8 trop petite dans le test\n",
    "X_test = X_test[np.where(y_test!=8)]\n",
    "y_test = y_test[np.where(y_test!=8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_sans_8_double_2\n",
    "y_train = y_train_sans_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (1000) in class 0 will be larger than the number of samples in the majority class (class #0 -> 141)\n",
      "  n_samples_majority))\n",
      "/usr/lib/python3.7/site-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (1000) in class 1 will be larger than the number of samples in the majority class (class #0 -> 141)\n",
      "  n_samples_majority))\n",
      "/usr/lib/python3.7/site-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (1000) in class 5 will be larger than the number of samples in the majority class (class #0 -> 141)\n",
      "  n_samples_majority))\n",
      "/usr/lib/python3.7/site-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (1000) in class 3 will be larger than the number of samples in the majority class (class #0 -> 141)\n",
      "  n_samples_majority))\n",
      "/usr/lib/python3.7/site-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (1000) in class -1 will be larger than the number of samples in the majority class (class #0 -> 141)\n",
      "  n_samples_majority))\n",
      "/usr/lib/python3.7/site-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (1000) in class 7 will be larger than the number of samples in the majority class (class #0 -> 141)\n",
      "  n_samples_majority))\n",
      "/usr/lib/python3.7/site-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (1000) in class 4 will be larger than the number of samples in the majority class (class #0 -> 141)\n",
      "  n_samples_majority))\n",
      "/usr/lib/python3.7/site-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (1000) in class 9 will be larger than the number of samples in the majority class (class #0 -> 141)\n",
      "  n_samples_majority))\n",
      "/usr/lib/python3.7/site-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (1000) in class 6 will be larger than the number of samples in the majority class (class #0 -> 141)\n",
      "  n_samples_majority))\n",
      "/usr/lib/python3.7/site-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (1000) in class 2 will be larger than the number of samples in the majority class (class #0 -> 141)\n",
      "  n_samples_majority))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-cdeb38f769e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0msmote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mX_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_resampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0my_resampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my_1\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my_1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_resampled\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_resampled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     83\u001b[0m             self.sampling_strategy, y, self._sampling_type)\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbinarize_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\u001b[0m in \u001b[0;36m_fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    794\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m             \u001b[0mnns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    813\u001b[0m             X_new, y_new = self._make_samples(X_class, y.dtype, class_sample,\n\u001b[1;32m    814\u001b[0m                                               X_class, nns, n_samples, 1.0)\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0;34m\"Expected n_neighbors <= n_samples, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0;34m\" but n_samples = %d, n_neighbors = %d\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m             )\n\u001b[1;32m    408\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6"
     ]
    }
   ],
   "source": [
    "# nombre d'occurences désirées par classe \n",
    "# # on a enlevé la classe 8 car qu'une occurence \n",
    "# impossible d'appliquer SMOTE ou ADASYN et génération d'une population à partir\n",
    "# d'un seul exemple est absurde\n",
    "\n",
    "dict= {0: 1000, 1: 1000, 5: 1000, 3: 1000, -1: 1000, 7: 1000, 4: 1000, 9: 1000, 6: 1000, 2: 1000}  \n",
    "smote = SMOTE(random_state=42, sampling_strategy=dict)\n",
    "\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "y_resampled = np.array([y_1 if y_1 != -1 else 8 for y_1 in y_resampled])\n",
    "print(set(y_resampled))\n",
    "print(X_resampled.shape)\n",
    "print(y_resampled.shape)\n",
    "\n",
    "with open('../starting_kit/sample_data/hadaca_feat1.name', 'w') as f:\n",
    "    for i in range(X_resampled.shape[1]):\n",
    "        f.write('methyl_{}\\n'.format(i))\n",
    "\n",
    "with open('../starting_kit/sample_data/hadaca_train.data', 'w') as f:\n",
    "    for x in X_resampled[50:100]:\n",
    "        for feat in x:\n",
    "            f.write('{} '.format(feat))\n",
    "\n",
    "        f.write('\\n')\n",
    "\n",
    "with open('../starting_kit/sample_data/hadaca_test.data', 'w') as f:\n",
    "    for x in X_resampled[:50]:\n",
    "        for feat in x:\n",
    "            f.write('{} '.format(feat))\n",
    "\n",
    "        f.write('\\n')\n",
    "\n",
    "\n",
    "with open('../starting_kit/sample_data/hadaca_valid.data', 'w') as f:\n",
    "    for x in X_resampled[100:150]:\n",
    "        for feat in x:\n",
    "            f.write('{} '.format(feat))\n",
    "\n",
    "        f.write('\\n')\n",
    "\n",
    "with open('../starting_kit/sample_data/hadaca_train.solution', 'w') as f:\n",
    "    for x in y_resampled[50:100]:\n",
    "        f.write('{}'.format(x))\n",
    "\n",
    "        f.write('\\n')\n",
    "\n",
    "with open('../starting_kit/sample_data/hadaca_test.solution', 'w') as f:\n",
    "    for x in y_resampled[:50]:\n",
    "        f.write('{}'.format(x))\n",
    "\n",
    "        f.write('\\n')\n",
    "\n",
    "\n",
    "with open('../starting_kit/sample_data/hadaca_valid.solution', 'w') as f:\n",
    "    for x in y_resampled[100:150]:\n",
    "        f.write('{}'.format(x))\n",
    "\n",
    "        f.write('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Classification par stage sur D\n",
    "\n",
    "NB: les données enrichies pour classifier sont dans X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-afb578cb1e07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mXGBclass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary:logistic'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mXGBclass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_resampled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_resampled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mpred_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBclass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_resampled\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# on vérifie que le train est normal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    698\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1045\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1046\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "\n",
    "XGBclass = XGBClassifier(objective='binary:logistic', max_depth=3, n_estimators=100, learning_rate=0.1, n_jobs=3)\n",
    "\n",
    "XGBclass.fit(X_resampled,y_resampled)\n",
    "pred_train = XGBclass.predict(X_resampled) # on vérifie que le train est normal\n",
    "\n",
    "print(\"Train:\")\n",
    "print(classification_report(y_resampled,pred_train))\n",
    "\n",
    "pred_test = XGBclass.predict(X_test)\n",
    "print(\"Test:\")\n",
    "print(classification_report(y_test,pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "\n",
    "RFclass = RandomForestClassifier(n_estimators = 200, max_depth = 20, n_jobs = 3)\n",
    "RFclass.fit(X_resampled,y_resampled)\n",
    "\n",
    "pred_train = RFclass.predict(X_resampled) # on vérifie que le train est normal\n",
    "\n",
    "print(\"Train:\")\n",
    "print(classification_report(y_resampled,pred_train))\n",
    "\n",
    "pred_test = RFclass.predict(X_test)\n",
    "print(\"Test:\")\n",
    "print(classification_report(y_test,pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "\n",
    "SVCclass = SVC(C=1)\n",
    "SVCclass.fit(X_resampled,y_resampled)\n",
    "pred_train = SVCclass.predict(X_resampled)\n",
    "\n",
    "print(\"Train:\")\n",
    "print(classification_report(y_resampled,pred_train))\n",
    "pred_test = SVCclass.predict(X_test)\n",
    "\n",
    "print(\"Test:\")\n",
    "print(classification_report(y_test,pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Factorisation de D en A*T\n",
    "\n",
    "comparer les résultats après facto NMF et facto TruncatedSVD ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(685, 100)\n",
      "(100, 1000)\n"
     ]
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components = 100)\n",
    "\n",
    "A = svd.fit_transform(D)\n",
    "T = svd.components_\n",
    "print(A.shape)\n",
    "print(T.shape)\n",
    "\n",
    "# qualité de la factorisation\n",
    "rmse = mean_squared_error(D,np.dot(A,T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Classification par stage sur A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "\n",
    "RFclass = RandomForestClassifier(n_estimators = 200, max_depth = 20, n_jobs = 3)\n",
    "RFclass.fit(X_resampled,y_resampled)\n",
    "\n",
    "pred_train = RFclass.predict(X_resampled) # on vérifie que le train est normal\n",
    "\n",
    "print(\"Train:\")\n",
    "print(classification_report(y_resampled,pred_train))\n",
    "\n",
    "pred_test = RFclass.predict(X_test)\n",
    "print(\"Test:\")\n",
    "print(classification_report(y_test,pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "\n",
    "SVCclass = SVC(C=1)\n",
    "SVCclass.fit(X_resampled,y_resampled)\n",
    "pred_train = SVCclass.predict(X_resampled)\n",
    "\n",
    "print(\"Train:\")\n",
    "print(classification_report(y_resampled,pred_train))\n",
    "pred_test = SVCclass.predict(A_test)\n",
    "\n",
    "print(\"Test:\")\n",
    "print(classification_report(y_test,pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Comparaison des classifications en partant de D et de A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
