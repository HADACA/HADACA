{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, mean_squared_error, log_loss\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import ADASYN, SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0) Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'clean_data.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d39a14f92188>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Chargement des données, clean_data étant les données nettoyées des NaN trop nombreux\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"clean_data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"df_data shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"metadata.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"df_metadata shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'clean_data.csv' does not exist"
     ]
    }
   ],
   "source": [
    "# Chargement des données, clean_data étant les données nettoyées des NaN trop nombreux\n",
    "df_data = pd.read_csv(\"clean_data.csv\")\n",
    "print(\"df_data shape:\", df_data.shape)\n",
    "df_metadata = pd.read_csv(\"metadata.csv\")\n",
    "print(\"df_metadata shape:\", df_metadata.shape)\n",
    "df_metadata[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(685, 20103)\n",
      "labelsBinary : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0\n",
      " 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "valuesBinary : Index(['patho', 'normal'], dtype='object')\n",
      "labelsStages : [ 0  0  1  2  0  3  1  4  0  1  0  3  0  5  0  0  5  1  0  6  4  1  1 -1\n",
      " -1  0  1  1  1  0  7 -1  7  0  0  1  4  5  0  0  8  5  6  9  5  7  6 -1\n",
      "  5  3  1  1  1  5  7  5  3 -1 -1  0  5  0  4  7  0  0 -1  1 -1  1  5 -1\n",
      "  5  5  0  1  5 -1  0  3  1  7  3  5  0  5  3  5  0 -1  5  3  0  1  1  0\n",
      " -1  3  7  0  1 -1  5  2  0  5  4  1  0  9  0  3  0  1  0  3  5 -1 -1  5\n",
      " -1  3  1  3  5  9  1  4  0  1  1 -1  5  0  5  0  3  1  1 -1 -1  1  0  0\n",
      "  7  3  1  0  0  3  5  1  1  0  0  0  0  1  3  1  3  1  3  3  1  0  1  0\n",
      "  9 -1 -1  3  0  5  1  7  1  1  1  4  7  3  0  3  5  5  9  1  0  7 -1  1\n",
      "  1  0  3  7  6  1  5  5  5  5  3  0  0  1  1  7  1  1 -1  0  1  0  7  7\n",
      "  0  0  3  0  1  5  1  1  7  0  0  7  1  1  1  1  7  9  7  0  1 -1 -1  0\n",
      "  6  1  0  5  7 -1  5  3  5  3  3  0  1  5  0  5  0  0  3  7  3  5  1  0\n",
      "  3  1  1  4  1  5  0  3  4  1  1  3  1  1  3  0  0  1  1  7  0  5  1  1\n",
      "  5  5  1  1 -1  1  5  0  1  1  3  5  4 -1  3  5 -1  4  7  3  3  0  5  7\n",
      "  0  1  1  1 -1  0  3 -1  3 -1 -1  0  0  1  5  3  1  1  4  3  0  7  0  7\n",
      "  7  3  0 -1  4  1  9  0  3  5  0  1  0  7  0 -1  1 -1  1  0  1  5 -1  0\n",
      "  1  0  1  0  3  1  7  5  1 -1  0  0 -1  1  3  4  0  1  0  3  0  1  6 -1\n",
      "  5  0  1  1  0 -1 -1  3  1  7  4  1  4 -1  3  3  1  2 -1  7  7  5  0  0\n",
      "  1  3  2  3  7  4  5  3  0  7  5 -1  3  0  1  1  1  1  7  3  7  9  1  9\n",
      " -1 -1  5  3  5  5  3  1  1  5  0  1  0  7 -1  4  0  0  3  3  1  0  4  1\n",
      "  0  1  5  1  0  7  0  3  1  1 -1  7 -1  3  0  5  0  7  2  0  1  0  1  1\n",
      "  0  7  5  0  0  1  0  5  0  0  0  0  7  3  3  7  0  1  3  0  7  4 -1  3\n",
      "  1  5  3  1  3  3  3  4  7  1  0  4  3  0  5  6  0  0  0  1  0  0  4  0\n",
      "  7 -1  3 -1  0  0  3  5  5  1  1  1  3  5  1  5  6 -1  3  5  3  0  0  5\n",
      "  1  1  1  7  5  7  0  5  0  3  1  0  0  0  3 -1  1  1  0  1  4 -1  1  0\n",
      "  1  5  0  1  0  9  1  5  5  5  1  5  4 -1  0  7  3  5 -1  0 -1  0 -1  4\n",
      "  0  1  1  4  6  1  0  0  5  0  4  0  1  5  9  9 -1  3  1  0  0  3  5  0\n",
      "  4  0  3  4  3  0  1  3  0  5  1  0  0  6  0  1  0  1  0  1  1  1  5  0\n",
      "  1  1  5  3  0  1  7  0  0  5  5  5  1  3  1  0  7  7  0  0  7  0  0  0\n",
      "  3  4  3  0  5  3  1  0  9  3  9  3  9]\n",
      "valuesStages : Index(['stage ib', 'stage ia', 'stage i', 'stage iib', 'stage iv',\n",
      "       'stage iiia', 'not reported', 'stage iia', 'stage ii', 'stage iiib'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Convertir les données en ndarray et supprimer les colonnes inutiles\n",
    "D = df_data.loc[:, ~df_data.columns.str.contains('^Unnamed')].values\n",
    "D = D.T\n",
    "\n",
    "print(type(D))\n",
    "print(D.shape)\n",
    "\n",
    "# Générer les labels en fonction d'une colonne choisie\n",
    "status = pd.Series(df_metadata[\"tissue_status\"].values)\n",
    "stage = pd.Series(df_metadata[\"tumor_stage\"].values)\n",
    "\n",
    "labelsBinary, valuesBinary = pd.factorize(status)\n",
    "labelsStages, valuesStages = pd.factorize(stage)\n",
    "\n",
    "yBinary = labelsBinary\n",
    "yStage = labelsStages\n",
    "\n",
    "print(\"labelsBinary :\", labelsBinary)\n",
    "print(\"valuesBinary :\", valuesBinary)\n",
    "\n",
    "print(\"labelsStages :\", labelsStages)\n",
    "print(\"valuesStages :\", valuesStages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(685, 1000)\n"
     ]
    }
   ],
   "source": [
    "# IL FAUT ARRIVER À 300 MB après avoir agrandi le nombre d'observations\n",
    "# ===>>> couper les features\n",
    "# selection des k best features grâce au test chi2\n",
    "chi2_selector = SelectKBest(chi2, k=1000)\n",
    "D = chi2_selector.fit_transform(D, labelsBinary)\n",
    "print(D.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enrichissement artificiel des données\n",
    "\n",
    "Problème potentiel: il reste peut-être des classes 8 dans le test set, potentiellement à nettoyer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 141, 1: 131, 5: 68, 3: 63, -1: 49, 7: 42, 4: 26, 9: 13, 6: 9, 2: 5, 8: 1})\n",
      "(547, 1000)\n",
      "(1000,)\n",
      "(548, 1000)\n",
      "[ 0  0  7  1  7  0  5  3  4 -1  0  0  5  0  7  0  6 -1  1  3  0  0  1  1\n",
      "  3 -1  1  5  1  5  0  3  0  4  7  7  3  3  0  0  1  0  0  0  4 -1 -1 -1\n",
      "  1  0  1  0 -1  0  9  6  5  0  0  0 -1  3  1  7  0  0  5  0  1  1  1  1\n",
      " -1  5  4  3  4  3 -1  0  7  0  5  1  1  6  1  9  1  0  7  5  1  1  0  5\n",
      "  7  0  5  0  3  0  3  0  0  6  7  0  1  1  5  3  7  0  1  5  5  1  1  7\n",
      "  0  1  0 -1 -1  0  1  0  0 -1  9  0 -1  0  3  1  0  7  5  1  3 -1  1  1\n",
      "  7  0  1  1  0  1  1  6  5  7  9  1  1  0  7  3  1  1  0  7  4  4  3  5\n",
      "  5  3  5 -1 -1  0  7  3  0  1  3  6  0  9  0  6  0  4  0  3 -1  1  7 -1\n",
      "  3  1  4  0  1  4  1  1  1  5  0 -1  9  1  0  1  1 -1  5  5  0 -1  3  4\n",
      "  0  1  7 -1  1  1  1  1  7  3  7  0  0  4  5  5  0  3  2  5  7 -1  1  7\n",
      "  0  5  1  0  1  1  0  1  3  1  5  1 -1  0  3  0  7  1  5  3  9 -1  0  5\n",
      "  1  1  5  1  9  9  3  3  0  0  1  1 -1 -1  5  1  1  1  0  0  0  2  0  0\n",
      "  6  0  3  0  5  5  5  1  7  1  7  7  7  5 -1  0  1  4 -1  5  5  4  5  1\n",
      "  0  3  5  5  1  1  1  1  5  5 -1  1  1 -1  0  0  0  4  1  0  3  5 -1  0\n",
      "  1  3  1  0 -1  0  5  0  1  0  3  1  9  3  0 -1  0  0  4  3  4  3  0  0\n",
      "  0  1  0  1  1  3  3  3  0  5  3  1  5  0  3  1  1 -1  5  0  0  3  0  4\n",
      "  7  1  1  3  4  5  0  0  7  5  1  9  1  0  2  4 -1  3  1  0  5  7  1  0\n",
      "  0  1  5  3  0  1  5  0  1  0  1  3 -1  5  1  1  0  6  0  1 -1  1  1 -1\n",
      "  5  0  0  0  3  7 -1  0 -1 -1  7  5  5  1  0  1  0  0  5  5  3  3  1  4\n",
      "  5  0  7  0  0  0  0  7  3  1  0  1  3  0  0  7  1  9  5  5  1  7  2  1\n",
      "  5  0 -1  0  1  3  1  1  0  3  3  4  7  3 -1  0  5  1  5  1  0  1  1  1\n",
      "  0  0  7  1  5  3  1  7  0  3 -1  2  0  1  1  1  1  3  1  1  0  4  0  0\n",
      "  3  3  1  0  0 -1  5  5  4  7 -1  3  9  4 -1  4  0  3  5]\n",
      "[ 0  0  7  1  7  0  5  3  4 -1  0  0  5  0  7  0  6 -1  1  3  0  0  1  1\n",
      "  3 -1  1  5  1  5  0  3  0  4  7  7  3  3  0  0  1  0  0  0  4 -1 -1 -1\n",
      "  1  0  1  0 -1  0  9  6  5  0  0  0 -1  3  1  7  0  0  5  0  1  1  1  1\n",
      " -1  5  4  3  4  3 -1  0  7  0  5  1  1  6  1  9  1  0  7  5  1  1  0  5\n",
      "  7  0  5  0  3  0  3  0  0  6  7  0  1  1  5  3  7  0  1  5  5  1  1  7\n",
      "  0  1  0 -1 -1  0  1  0  0 -1  9  0 -1  0  3  1  0  7  5  1  3 -1  1  1\n",
      "  7  0  1  1  0  1  1  6  5  7  9  1  1  0  7  3  1  1  0  7  4  4  3  5\n",
      "  5  3  5 -1 -1  0  7  3  0  1  3  6  0  9  0  6  0  4  0  3 -1  1  7 -1\n",
      "  3  1  4  0  1  4  1  1  1  5  0 -1  9  1  0  1  1 -1  5  5  0 -1  3  4\n",
      "  0  1  7 -1  1  1  1  1  7  3  7  0  0  4  5  5  0  3  2  5  7 -1  1  7\n",
      "  0  5  1  0  1  1  0  1  3  1  5  1 -1  0  3  0  7  1  5  3  9 -1  0  5\n",
      "  1  1  5  1  9  9  3  3  0  0  1  1 -1 -1  5  1  1  1  0  0  0  2  0  0\n",
      "  6  0  3  0  5  5  5  1  7  1  7  7  7  5 -1  0  1  4 -1  5  5  4  5  1\n",
      "  0  3  5  5  1  1  1  1  5  5 -1  1  1 -1  0  0  0  4  1  0  3  5 -1  0\n",
      "  1  3  1  0 -1  0  5  0  1  0  3  1  9  3  0 -1  0  0  4  3  4  3  0  0\n",
      "  0  1  0  1  1  3  3  3  0  5  3  1  5  0  3  1  1 -1  5  0  0  3  0  4\n",
      "  7  1  1  3  4  5  0  0  7  5  1  9  1  0  2  4 -1  3  1  0  5  7  1  0\n",
      "  0  1  5  3  0  1  5  0  1  0  1  3 -1  5  1  1  0  6  0  1 -1  1  1 -1\n",
      "  5  0  0  0  3  7 -1  0 -1 -1  7  5  5  1  0  1  0  0  5  5  3  3  1  4\n",
      "  5  0  7  0  0  0  0  7  3  1  0  1  3  0  0  7  1  9  5  5  1  7  2  1\n",
      "  5  0 -1  0  1  3  1  1  0  3  3  4  7  3 -1  0  5  1  5  1  0  1  1  1\n",
      "  0  0  7  1  5  3  1  7  0  3 -1  2  0  1  1  1  1  3  1  1  0  4  0  0\n",
      "  3  3  1  0  0 -1  5  5  4  7 -1  3  9  4 -1  4  0  3  5  2]\n"
     ]
    }
   ],
   "source": [
    "# 6 occurences nécessaire pour Smote ou Adasyn, \n",
    "# on enlève la classe 8 et on duplique une occurence de 2 pour passer à 6 (min SMOTE) \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(D, yStage, test_size=0.2, random_state=42)\n",
    "# stratify=y, mais une classe avec 1 occurences,on vire cette classe?\n",
    "\n",
    "recounted = Counter(y_train)\n",
    "print(recounted)\n",
    "\n",
    "X_train_sans_8 = X_train[np.where(y_train!=8)]\n",
    "X_2 = X_train[np.where(y_train==2)][0]\n",
    "print(X_train_sans_8.shape)\n",
    "print(X_2.shape)\n",
    "\n",
    "# dédoublement d'un exemple de la classe 2\n",
    "X_train_sans_8_double_2 = np.vstack([X_train_sans_8,X_2])\n",
    "print(X_train_sans_8_double_2.shape)\n",
    "\n",
    "# dédoublement d'un label de la classe 2\n",
    "y_train_sans_8 = y_train[np.where(y_train!=8)]\n",
    "print(y_train_sans_8)\n",
    "y_train_sans_8 = np.append(y_train_sans_8, 2)\n",
    "print(y_train_sans_8)\n",
    "\n",
    "# retrait des instances potentielles de la classe 8 trop petite dans le test\n",
    "X_test = X_test[np.where(y_test!=8)]\n",
    "y_test = y_test[np.where(y_test!=8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_sans_8_double_2\n",
    "y_train = y_train_sans_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mbauw/anaconda3/lib/python3.7/site-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (1000) in class 0 will be larger than the number of samples in the majority class (class #0 -> 141)\n",
      "  n_samples_majority))\n",
      "/home/mbauw/anaconda3/lib/python3.7/site-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (1000) in class 1 will be larger than the number of samples in the majority class (class #0 -> 141)\n",
      "  n_samples_majority))\n",
      "/home/mbauw/anaconda3/lib/python3.7/site-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (1000) in class 5 will be larger than the number of samples in the majority class (class #0 -> 141)\n",
      "  n_samples_majority))\n",
      "/home/mbauw/anaconda3/lib/python3.7/site-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (1000) in class 3 will be larger than the number of samples in the majority class (class #0 -> 141)\n",
      "  n_samples_majority))\n",
      "/home/mbauw/anaconda3/lib/python3.7/site-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (1000) in class -1 will be larger than the number of samples in the majority class (class #0 -> 141)\n",
      "  n_samples_majority))\n",
      "/home/mbauw/anaconda3/lib/python3.7/site-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (1000) in class 7 will be larger than the number of samples in the majority class (class #0 -> 141)\n",
      "  n_samples_majority))\n",
      "/home/mbauw/anaconda3/lib/python3.7/site-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (1000) in class 4 will be larger than the number of samples in the majority class (class #0 -> 141)\n",
      "  n_samples_majority))\n",
      "/home/mbauw/anaconda3/lib/python3.7/site-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (1000) in class 9 will be larger than the number of samples in the majority class (class #0 -> 141)\n",
      "  n_samples_majority))\n",
      "/home/mbauw/anaconda3/lib/python3.7/site-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (1000) in class 6 will be larger than the number of samples in the majority class (class #0 -> 141)\n",
      "  n_samples_majority))\n",
      "/home/mbauw/anaconda3/lib/python3.7/site-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (1000) in class 2 will be larger than the number of samples in the majority class (class #0 -> 141)\n",
      "  n_samples_majority))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1000)\n",
      "(548, 1000)\n"
     ]
    }
   ],
   "source": [
    "# nombre d'occurences désirées par classe \n",
    "# # on a enlevé la classe 8 car qu'une occurence \n",
    "# impossible d'appliquer SMOTE ou ADASYN et génération d'une population à partir\n",
    "# d'un seul exemple est absurde\n",
    "\n",
    "dict= {0: 1000, 1: 1000, 5: 1000, 3: 1000, -1: 1000, 7: 1000, 4: 1000, 9: 1000, 6: 1000, 2: 1000}  \n",
    "smote = SMOTE(random_state=42, sampling_strategy=dict)\n",
    "\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "print(X_resampled.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Classification par stage sur D\n",
    "\n",
    "NB: les données enrichies pour classifier sont dans X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00      1000\n",
      "           0       1.00      0.99      0.99      1000\n",
      "           1       1.00      1.00      1.00      1000\n",
      "           2       1.00      1.00      1.00      1000\n",
      "           3       1.00      1.00      1.00      1000\n",
      "           4       1.00      1.00      1.00      1000\n",
      "           5       1.00      1.00      1.00      1000\n",
      "           6       1.00      1.00      1.00      1000\n",
      "           7       1.00      1.00      1.00      1000\n",
      "           9       1.00      1.00      1.00      1000\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     10000\n",
      "   macro avg       1.00      1.00      1.00     10000\n",
      "weighted avg       1.00      1.00      1.00     10000\n",
      "\n",
      "Test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      1.00      0.92        12\n",
      "           0       0.15      0.20      0.17        30\n",
      "           1       0.28      0.30      0.29        27\n",
      "           3       0.14      0.07      0.10        28\n",
      "           4       0.00      0.00      0.00         5\n",
      "           5       0.13      0.10      0.11        21\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.10      0.09      0.10        11\n",
      "           9       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.23      0.23      0.23       137\n",
      "   macro avg       0.18      0.19      0.19       137\n",
      "weighted avg       0.22      0.23      0.22       137\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mbauw/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "\n",
    "XGBclass = XGBClassifier(objective='binary:logistic', max_depth=3, n_estimators=100, learning_rate=0.1, n_jobs=3)\n",
    "\n",
    "XGBclass.fit(X_resampled,y_resampled)\n",
    "pred_train = XGBclass.predict(X_resampled) # on vérifie que le train est normal\n",
    "\n",
    "print(\"Train:\")\n",
    "print(classification_report(y_resampled,pred_train))\n",
    "\n",
    "pred_test = XGBclass.predict(X_test)\n",
    "print(\"Test:\")\n",
    "print(classification_report(y_test,pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00      1000\n",
      "           0       1.00      1.00      1.00      1000\n",
      "           1       1.00      1.00      1.00      1000\n",
      "           2       1.00      1.00      1.00      1000\n",
      "           3       1.00      1.00      1.00      1000\n",
      "           4       1.00      1.00      1.00      1000\n",
      "           5       1.00      1.00      1.00      1000\n",
      "           6       1.00      1.00      1.00      1000\n",
      "           7       1.00      1.00      1.00      1000\n",
      "           9       1.00      1.00      1.00      1000\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     10000\n",
      "   macro avg       1.00      1.00      1.00     10000\n",
      "weighted avg       1.00      1.00      1.00     10000\n",
      "\n",
      "Test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.55      1.00      0.71        12\n",
      "           0       0.19      0.37      0.25        30\n",
      "           1       0.38      0.44      0.41        27\n",
      "           3       0.14      0.04      0.06        28\n",
      "           4       0.00      0.00      0.00         5\n",
      "           5       0.25      0.14      0.18        21\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00        11\n",
      "           9       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.28      0.28      0.28       137\n",
      "   macro avg       0.17      0.22      0.18       137\n",
      "weighted avg       0.23      0.28      0.24       137\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mbauw/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Random forest\n",
    "\n",
    "RFclass = RandomForestClassifier(n_estimators = 200, max_depth = 20, n_jobs = 3)\n",
    "RFclass.fit(X_resampled,y_resampled)\n",
    "\n",
    "pred_train = RFclass.predict(X_resampled) # on vérifie que le train est normal\n",
    "\n",
    "print(\"Train:\")\n",
    "print(classification_report(y_resampled,pred_train))\n",
    "\n",
    "pred_test = RFclass.predict(X_test)\n",
    "print(\"Test:\")\n",
    "print(classification_report(y_test,pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mbauw/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.85      0.98      0.91      1000\n",
      "           0       0.34      0.48      0.39      1000\n",
      "           1       0.28      0.61      0.38      1000\n",
      "           2       1.00      1.00      1.00      1000\n",
      "           3       0.91      0.14      0.25      1000\n",
      "           4       0.74      0.60      0.66      1000\n",
      "           5       0.98      0.10      0.17      1000\n",
      "           6       1.00      0.83      0.91      1000\n",
      "           7       0.49      0.73      0.58      1000\n",
      "           9       0.97      0.80      0.88      1000\n",
      "\n",
      "   micro avg       0.63      0.63      0.63     10000\n",
      "   macro avg       0.76      0.63      0.61     10000\n",
      "weighted avg       0.76      0.63      0.61     10000\n",
      "\n",
      "Test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.57      1.00      0.73        12\n",
      "           0       0.25      0.27      0.26        30\n",
      "           1       0.27      0.30      0.28        27\n",
      "           3       0.00      0.00      0.00        28\n",
      "           4       0.00      0.00      0.00         5\n",
      "           5       0.00      0.00      0.00        21\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.12      0.36      0.18        11\n",
      "           9       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.23      0.23      0.23       137\n",
      "   macro avg       0.13      0.21      0.16       137\n",
      "weighted avg       0.17      0.23      0.19       137\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mbauw/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "\n",
    "SVCclass = SVC(C=1)\n",
    "SVCclass.fit(X_resampled,y_resampled)\n",
    "pred_train = SVCclass.predict(X_resampled)\n",
    "\n",
    "print(\"Train:\")\n",
    "print(classification_report(y_resampled,pred_train))\n",
    "pred_test = SVCclass.predict(X_test)\n",
    "\n",
    "print(\"Test:\")\n",
    "print(classification_report(y_test,pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Factorisation de D en A*T\n",
    "\n",
    "comparer les résultats après facto NMF et facto TruncatedSVD ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(685, 100)\n",
      "(100, 1000)\n"
     ]
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components = 100)\n",
    "\n",
    "A = svd.fit_transform(D)\n",
    "T = svd.components_\n",
    "print(A.shape)\n",
    "print(T.shape)\n",
    "\n",
    "# qualité de la factorisation\n",
    "rmse = mean_squared_error(D,np.dot(A,T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Classification par stage sur A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "\n",
    "RFclass = RandomForestClassifier(n_estimators = 200, max_depth = 20, n_jobs = 3)\n",
    "RFclass.fit(X_resampled,y_resampled)\n",
    "\n",
    "pred_train = RFclass.predict(X_resampled) # on vérifie que le train est normal\n",
    "\n",
    "print(\"Train:\")\n",
    "print(classification_report(y_resampled,pred_train))\n",
    "\n",
    "pred_test = RFclass.predict(X_test)\n",
    "print(\"Test:\")\n",
    "print(classification_report(y_test,pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "\n",
    "SVCclass = SVC(C=1)\n",
    "SVCclass.fit(X_resampled,y_resampled)\n",
    "pred_train = SVCclass.predict(X_resampled)\n",
    "\n",
    "print(\"Train:\")\n",
    "print(classification_report(y_resampled,pred_train))\n",
    "pred_test = SVCclass.predict(A_test)\n",
    "\n",
    "print(\"Test:\")\n",
    "print(classification_report(y_test,pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Comparaison des classifications en partant de D et de A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
